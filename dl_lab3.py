# -*- coding: utf-8 -*-
"""DL-lab3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155bUtMUa9ovgBpeEjY4ne-yCGyBTZUB_
"""

import torch
import torch.optim as optim

"""1.1 Rastrigin function"""

import math 
from typing import Tuple

def rastrigin(X) -> Tuple[torch.Tensor, torch.tensor]:
  n = 2
  A = 1.0
  f = A*n + sum([(x**2 - A * math.cos(2 * math.pi * x)) for x in X])
  
  return f

"""Optimisation using sgd with lr = 0.01"""

X = torch.tensor([5.0,5.0], requires_grad=True)
epochs = 100

opt = optim.SGD([X], lr=0.01)
loss_values = []
for i in range(epochs):
    opt.zero_grad()
    output = rastrigin(X)
    loss_values.append(output.tolist())
    output.backward()
    opt.step()

print("Value of X after 100 iterations", X)
print(loss_values)

"""Plot sgd with lr = 0.01"""

import matplotlib.pyplot as plt

x = [x for x in range(1,101)]
y = loss_values
plt.plot(x , y)

plt.xlabel(" Rastrigin function parameter X")
plt.ylabel(" Number of epochs ")
plt.title(" Loss plot for Rastrigin function using SGD")
plt.show()

"""Optimisation using sgd with lr = 0.01 and momentum =0.9"""

X = torch.tensor([5.0,5.0], requires_grad=True)
epochs = 100

opt = optim.SGD([X], lr=0.01, momentum = 0.9)
loss_values_sgdm = []
for i in range(epochs):
    opt.zero_grad()
    output = rastrigin(X)
    loss_values_sgdm.append(output.tolist())
    output.backward()
    opt.step()

print(X)

import matplotlib.pyplot as plt

x = [x for x in range(1,101)]
y = loss_values_sgdm
plt.plot(x , y)

plt.xlabel(" Rastrigin function parameter X")
plt.ylabel(" Number of epochs ")
plt.title(" Loss plot for Rastrigin function using SGD+ Momentum")
plt.show()

"""Optimisation using adsgd with lr = 0.01"""



"""Optimisation using adam with lr = 0.01"""

X = torch.tensor([5.0,5.0], requires_grad=True)
epochs = 100

opt = optim.Adam([X], lr=0.01)
loss_values_adam = []
for i in range(epochs):
    opt.zero_grad()
    output = rastrigin(X)
    loss_values_adam.append(output.tolist())
    output.backward()
    opt.step()

print(X)

import matplotlib.pyplot as plt

x = [x for x in range(1,101)]
y = loss_values_adam
plt.plot(x , y)

plt.xlabel(" Rastrigin function parameter X")
plt.ylabel(" Number of epochs ")
plt.title(" Loss plot for Rastrigin function using SGD+ Momentum")
plt.show()

"""2 Optimisation of SVM on real data"""

try: 
    from celluloid import Camera
except:
    !pip install celluloid

from IPython.display import HTML
import torch
import torch.optim as optim

import torch
import pandas as pd

df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases'+'/iris/iris.data', header = None)
df = df.sample(frac =1 , random_state =0) #shuffle

df = df[df[4].isin(['Iris-virginca' , 'Iris-versicolor'])] #filter
# add label indices column
mapping = {k : v for v,k in enumerate(df[4].unique())}
df[5] = ( 2* df[4].map(mapping)) -1  #labels in {-1,1}

# normalise data
alldata = torch.tensor(df.iloc[:,[0 , 1, 2, 3]].values , dtype = torch.float)
alldata = (alldata - alldata.mean(dim=0)) / alldata.var(dim = 0)
# create datasets 
targets_tr = torch.tensor(df.iloc[:25, 5].values, dtype = torch.float)
targets_va = torch.tensor(df.iloc[25: , 5].values, dtype = torch.float)
data_tr = alldata[:25]
data_va = alldata[25:]
print(targets_va)

def hinge_loss(y_pred, y_true):
  return torch.mean(torch.clamp(1 - y_pred.mul(y_true), min=0))

def svm(x, w, b):
    h = (w*x).sum(1) + b
    return h

from torch.utils import data
# print(targets_tr)

train_dataset = data.TensorDataset(data_tr,targets_tr) # create your datset
test_dataset = data.TensorDataset(data_va , targets_va)
train_dataloader = data.DataLoader(train_dataset, batch_size=25, shuffle=True) # create your dataloader
test_dataloader = data.DataLoader(test_dataset , batch_size = 25, shuffle = True)

def classification(X):
  Y = []
  for i in range(len(X)):
    if X[i]<0:
      Y.append(-1)
    else:
      Y.append(0)
      
  return torch.tensor(Y , dtype = torch.float)

"""With sgd"""

w = torch.randn(1, 4, requires_grad=True, dtype=torch.float)
b = torch.randn(1, requires_grad=True, dtype=torch.float)
# print(w.shape, b.shape)
opt = optim.SGD([w,b], lr=0.01, weight_decay=0.0001)
for epoch in range(100):
    for batch in train_dataloader:
      opt.zero_grad()
      output = hinge_loss(svm(batch[0], w, b), batch[1] )
      output.backward()
      opt.step()

print(w,b)

y_pred = classification(svm(data_va , w, b).tolist())
print(y_pred)

# Compute the model accuracy on the test set with SGD 
correct = 0
total = y_pred.size()[0]

for i in range(y_pred.size()[0]):
  if y_pred[i] == targets_va[i]:
    correct +=1

print('Test Accuracy: %2.2f %%' % ((100.0 * correct) / total))

"""With adam"""

w = torch.randn(1, 4, requires_grad=True, dtype=torch.float)
b = torch.randn(1, requires_grad=True, dtype=torch.float)
# print(w.shape, b.shape)
opt = optim.Adam([w,b], lr=0.01, weight_decay=0.0001)
for epoch in range(100):
    for batch in train_dataloader:
      opt.zero_grad()
      output = hinge_loss(svm(batch[0], w, b), batch[1] )
      output.backward()
      opt.step()

print(w,b)

y_pred = classification(svm(data_va , w, b).tolist())
print(y_pred)

# Compute the model accuracy on the test set
correct = 0
total = y_pred.size()[0]

for i in range(y_pred.size()[0]):
  if y_pred[i] == targets_va[i]:
    correct +=1

print('Test Accuracy: %2.2f %%' % ((100.0 * correct) / total))

